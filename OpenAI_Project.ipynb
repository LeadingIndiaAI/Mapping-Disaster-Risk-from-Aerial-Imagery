{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pyproj\n",
    "!pip install rasterio\n",
    "!pip install geopandas\n",
    "!pip install pandas\n",
    "!pip install shapely\n",
    "!pip install os\n",
    "!pip install fastai\n",
    "!pip install torchvision\n",
    "!pip install efficientnet_pytorch\n",
    "!pip install keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For Image PreProcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyproj import Proj, transform\n",
    "from rasterio.mask import mask\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "import shapely\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For PreTrained Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tT9IIdlEG0az"
   },
   "outputs": [],
   "source": [
    "from fastai.callbacks import SaveModelCallback\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from fastai.vision.learner import model_meta\n",
    "from fastai.metrics import error_rate\n",
    "from fastai.vision.models import *\n",
    "from torchvision.models import *\n",
    "from fastai.vision import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Pre-Processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Path of the raw data folder with the GeoTiff, GeoJSON and JSON files.\n",
    "source_path = 'stac'\n",
    "\n",
    "#Path to the extracted images.\n",
    "dest_path = 'Processed_data'\n",
    "\n",
    "#To track the number of images that are processed and their order.\n",
    "testImg_pos = 0\n",
    "\n",
    "#The countries whose images are being processed\n",
    "countries = ['colombia','guatemala','st_lucia']\n",
    "\n",
    "#The countries as keys and their respective epsg ids as values\n",
    "epsg = {'colombia':'32618', 'guatemala':'32616', 'st_lucia':'32620'}\n",
    "\n",
    "#The regions that are processesd with their respective countries as their keys\n",
    "regions = {'st_lucia':['dennery'], 'colombia':['borde_rural','borde_soacha'], \n",
    "           'guatemala':['mixco_1_and_ebenezer','mixco_3']}\n",
    "\n",
    "#For ease of looping\n",
    "cases = ['train', 'test']\n",
    "\n",
    "#To store the ids of the rooftops in the order that they where extracted\n",
    "ids = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Directories to store extracted images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "materials = [\"concrete_cement\",\"healthy_metal\",\"incomplete\",\"irregular_metal\",\"other\"]\n",
    "for name in materials:\n",
    "    os.makedirs(dest_path+'/train/'+name)\n",
    "os.makedirs(dest_path+'/test/data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extacting rooftops from the GeoTIFF image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for country in countries:\n",
    "    inProj = Proj(init = 'epsg:4326')\n",
    "    outProj = Proj(init = 'epsg:'+epsg[country])\n",
    "    for region in regions[country]:\n",
    "        src = rasterio.open(source_path+'/'+country+'/'+region+'/'+region+'_ortho-cog.tif')\n",
    "        for case in cases:\n",
    "            aoi_geojson = gpd.read_file(data_path+'/'+country+'/'+region+'/'+case+'-'+region+'.geojson')\n",
    "            for i in range(aoi_geojson.shape[0]):\n",
    "                cord = aoi_geojson['geometry'][i].bounds\n",
    "                (x1,y1,x2,y2) = cord\n",
    "                x1_new,y1_new = transform(inProj,outProj,x1,y1)\n",
    "                x2_new,y2_new = transform(inProj,outProj,x2,y2)\n",
    "                ar_new = shapely.geometry.box(x1_new, y1_new, x2_new, y2_new, ccw=True)\n",
    "                crop, cropTransform = mask(src, [ar_new], crop=True)\n",
    "                meta = src.meta.copy()\n",
    "                meta.update({'transform':cropTransform, 'height':crop.shape[1], 'width':crop.shape[2]})\n",
    "                if case == 'train':\n",
    "                    with rasterio.open(dest_path+'/'+case+'/'+aoi_geojson['roof_material'][i]+'/'+aoi_geojson['id'][i]+'.tif', 'w', **meta) as dst:\n",
    "                        dst.write(crop)\n",
    "                if case == 'test':\n",
    "                    testImg_pos = testImg_pos+1\n",
    "                    with rasterio.open(dest_path+'/'+case+'/data/'+str(testImg_pos)+'.tif', 'w', **meta) as dst:\n",
    "                        dst.write(crop)\n",
    "                        ids.append(aoi_geojson['id'][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Using PreTrained Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Image Data Bunch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2) #Everytime the same validation bunch is taken\n",
    "\n",
    "data = ImageDataBunch.from_folder(dest_path,train='train', test = 'test',valid_pct = 0.2,  ds_tfms=get_transforms(flip_vert=True, max_lighting=0.1, max_zoom=1.05, max_warp=0.), \n",
    "                              size=256, bs=32).normalize(imagenet_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funtion for Finding the optimum learning rate (Future Work)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-thYTxkCOlP7"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Giving a much Larger Value than what is being expected.\n",
    "\n",
    "def find_appropriate_lr(model:Learner, lr_diff:int = 15, loss_threshold:float = .05, adjust_value:float = 1, plot:bool = False) -> float:\n",
    "    #Run the Learning Rate Finder\n",
    "    model.lr_find()\n",
    "    \n",
    "    #Get loss values and their corresponding gradients, and get lr values\n",
    "    losses = np.array(model.recorder.losses)\n",
    "    assert(lr_diff < len(losses))\n",
    "    loss_grad = np.gradient(losses)\n",
    "    lrs = model.recorder.lrs\n",
    "    \n",
    "    #Search for index in gradients where loss is lowest before the loss spike\n",
    "    #Initialize right and left idx using the lr_diff as a spacing unit\n",
    "    #Set the local min lr as -1 to signify if threshold is too low\n",
    "    r_idx = -1\n",
    "    l_idx = r_idx - lr_diff\n",
    "    while (l_idx >= -len(losses)) and (abs(loss_grad[r_idx] - loss_grad[l_idx]) > loss_threshold):\n",
    "        local_min_lr = lrs[l_idx]\n",
    "        r_idx -= 1\n",
    "        l_idx -= 1\n",
    "\n",
    "    lr_to_use = local_min_lr * adjust_value\n",
    "    \n",
    "    if plot:\n",
    "        # plots the gradients of the losses in respect to the learning rate change\n",
    "        plt.plot(loss_grad)\n",
    "        plt.plot(len(losses)+l_idx, loss_grad[l_idx],markersize=10,marker='o',color='red')\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.xlabel(\"Index of LRs\")\n",
    "        plt.show()\n",
    "\n",
    "        plt.plot(np.log10(lrs), losses)\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.xlabel(\"Log 10 Transform of Learning Rate\")\n",
    "        loss_coord = np.interp(np.log10(lr_to_use), np.log10(lrs), losses)\n",
    "        plt.plot(np.log10(lr_to_use), loss_coord, markersize=10,marker='o',color='red')\n",
    "        plt.show()\n",
    "        \n",
    "    return lr_to_use '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the PreTrained Model and Training it's final layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "22HZrVOeYWfd",
    "outputId": "68c50c29-5f63-4a65-d3f8-4b2b95eaa006"
   },
   "outputs": [],
   "source": [
    "model = EfficientNet.from_pretrained('efficientnet-b7', num_classes=data.c)\n",
    "\n",
    "model._fc = nn.Linear(in_features=2560, out_features=5, bias=True) #Attaching a Linear layer at the end to support 5 classes\n",
    "\n",
    "learn = Learner(data, model, metrics=[error_rate]).mixup().to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "22HZrVOeYWfd",
    "outputId": "68c50c29-5f63-4a65-d3f8-4b2b95eaa006"
   },
   "outputs": [],
   "source": [
    "learn.lr_find()\n",
    "learn.recorder.plot(suggestion=True)\n",
    "\n",
    "#Step of manually choosing the learning rate\n",
    "lr = 1e-05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-thYTxkCOlP7"
   },
   "outputs": [],
   "source": [
    "#The Function needs to be improvised\n",
    "#lr = find_appropriate_lr(learn, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "22HZrVOeYWfd",
    "outputId": "68c50c29-5f63-4a65-d3f8-4b2b95eaa006"
   },
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(20, max_lr = slice(lr) ,callbacks=[SaveModelCallback(learn)])\n",
    "learn.load('bestmodel')\n",
    "learn.save('efficient_net_b7_v2_best')\n",
    "\n",
    "#Analysis of the best model found\n",
    "learn.recorder.plot_losses()\n",
    "learn.recorder.plot_lr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making all the layers of the model trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "22HZrVOeYWfd",
    "outputId": "68c50c29-5f63-4a65-d3f8-4b2b95eaa006"
   },
   "outputs": [],
   "source": [
    "learn.unfreeze() # Making all the layers within the pretrained model trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "22HZrVOeYWfd",
    "outputId": "68c50c29-5f63-4a65-d3f8-4b2b95eaa006"
   },
   "outputs": [],
   "source": [
    "#training the unfreezed model\n",
    "learn.lr_find()\n",
    "learn.recorder.plot(suggestion=True)\n",
    "\n",
    "#Choosing the learning rate manually\n",
    "lr = 1e-05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "22HZrVOeYWfd",
    "outputId": "68c50c29-5f63-4a65-d3f8-4b2b95eaa006"
   },
   "outputs": [],
   "source": [
    "#lr = find_appropriate_lr(learn, plot=True) (Function needs to be refined and optimised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "22HZrVOeYWfd",
    "outputId": "68c50c29-5f63-4a65-d3f8-4b2b95eaa006"
   },
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(10, max_lr=slice(lr), callbacks=[SaveModelCallback(learn)])\n",
    "\n",
    "learn.load('bestmodel')\n",
    "learn.save('efficient_net_b7_v2_unfreeze_best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "for img_id in ids:\n",
    "    img = open_image(dest_path+'/'+'test/'+img_id+'.tif')\n",
    "    result.append(np.array(learn.predict(img)[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the Results in .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NnU_fNF3GS0T"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(result, columns = ['concrete_cement','healthy_metal','incomplete','irregular_metal','other'])\n",
    "df.insert(0,'id',ids)\n",
    "df.to_csv(dest_path+'/'+'Submission Form.csv',index = False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Model_Satellite_efficientnet.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
