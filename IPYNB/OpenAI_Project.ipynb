{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyproj import Proj, transform\n",
    "from rasterio.mask import mask\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "import shapely\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tT9IIdlEG0az"
   },
   "outputs": [],
   "source": [
    "from fastai.callbacks import SaveModelCallback\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from fastai.vision.learner import model_meta\n",
    "from fastai.metrics import error_rate\n",
    "from fastai.vision.models import *\n",
    "from torchvision.models import *\n",
    "from fastai.vision import *\n",
    "import pretrainedmodels\n",
    "from utils import *\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Pre-Processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "materials = [\"concrete_cement\",\"healthy_metal\",\"incomplete\",\"irregular_metal\",\"other\"]\n",
    "for name in materials:\n",
    "    os.makedirs('/home/cupgreek/Documents/Processed_data/train/'+name)\n",
    "os.makedirs('/home/cupgreek/Documents/Processed_data/test/data')\n",
    "\n",
    "#Function to extract the rooftop image from the source image and save it in '.tif' format\n",
    "num = 0\n",
    "epsg = {'colombia':'32618', 'guatemala':'32616', 'st_lucia':'32620'}\n",
    "regions = {'st_lucia':['dennery'], 'colombia':['borde_rural','borde_soacha'], \n",
    "           'guatemala':['mixco_1_and_ebenezer','mixco_3']}\n",
    "ids = []\n",
    "\n",
    "for country in ['colombia','guatemala','st_lucia']:\n",
    "    inProj = Proj(init = 'epsg:4326')\n",
    "    outProj = Proj(init = 'epsg:'+epsg[country])\n",
    "    for region in regions[country]:\n",
    "        src = rasterio.open('/home/cupgreek/Documents/stac/'+country+'/'+region+'/'+region+'_ortho-cog.tif')\n",
    "        for case in ['train', 'test']:\n",
    "            aoi_geojson = gpd.read_file('/home/cupgreek/Documents/stac/'+country+'/'+region+'/'+case+'-'+region+'.geojson')\n",
    "            for i in range(aoi_geojson.shape[0]):\n",
    "                cord = aoi_geojson['geometry'][i].bounds\n",
    "                (x1,y1,x2,y2) = cord\n",
    "                x1_new,y1_new = transform(inProj,outProj,x1,y1)\n",
    "                x2_new,y2_new = transform(inProj,outProj,x2,y2)\n",
    "                ar_new = shapely.geometry.box(x1_new, y1_new, x2_new, y2_new, ccw=True)\n",
    "                crop, cropTransform = mask(src, [ar_new], crop=True)\n",
    "                meta = src.meta.copy()\n",
    "                meta.update({'transform':cropTransform, 'height':crop.shape[1], 'width':crop.shape[2]})\n",
    "                if case == 'train':\n",
    "                    with rasterio.open('/home/cupgreek/Documents/Processed_data/'+case+'/'+aoi_geojson['roof_material'][i]+'/'+aoi_geojson['id'][i]+'.tif', 'w', **meta) as dst:\n",
    "                        dst.write(crop)\n",
    "                if case == 'test':\n",
    "                    num = num+1\n",
    "                    with rasterio.open('/home/cupgreek/Documents/Processed_data/'+case+'/data'+str(num)+'.tif', 'w', **meta) as dst:\n",
    "                        dst.write(crop)\n",
    "                        ids.append(aoi_geojson['id'][i])        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the Image Data Bunch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2) # Everytime same validation bunch is taken\n",
    "data = ImageDataBunch.from_folder('/content/drive/My Drive/Satellite data/data_processed/train',train='', test = '/content/drive/My Drive/Satellite data/data_processed/test',valid_pct = 0.2,  ds_tfms=get_transforms(flip_vert=True, max_lighting=0.1, max_zoom=1.05, max_warp=0.), \n",
    "                              size=256, bs=32).normalize(imagenet_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Using PreTrained Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-thYTxkCOlP7"
   },
   "outputs": [],
   "source": [
    "#Funtion for Finding the optimum learning rate (For now doing it manually)\n",
    "'''def find_appropriate_lr(model:Learner, lr_diff:int = 15, loss_threshold:float = .05, adjust_value:float = 1, plot:bool = False) -> float:\n",
    "    #Run the Learning Rate Finder\n",
    "    model.lr_find()\n",
    "    \n",
    "    #Get loss values and their corresponding gradients, and get lr values\n",
    "    losses = np.array(model.recorder.losses)\n",
    "    assert(lr_diff < len(losses))\n",
    "    loss_grad = np.gradient(losses)\n",
    "    lrs = model.recorder.lrs\n",
    "    \n",
    "    #Search for index in gradients where loss is lowest before the loss spike\n",
    "    #Initialize right and left idx using the lr_diff as a spacing unit\n",
    "    #Set the local min lr as -1 to signify if threshold is too low\n",
    "    r_idx = -1\n",
    "    l_idx = r_idx - lr_diff\n",
    "    while (l_idx >= -len(losses)) and (abs(loss_grad[r_idx] - loss_grad[l_idx]) > loss_threshold):\n",
    "        local_min_lr = lrs[l_idx]\n",
    "        r_idx -= 1\n",
    "        l_idx -= 1\n",
    "\n",
    "    lr_to_use = local_min_lr * adjust_value\n",
    "    \n",
    "    if plot:\n",
    "        # plots the gradients of the losses in respect to the learning rate change\n",
    "        plt.plot(loss_grad)\n",
    "        plt.plot(len(losses)+l_idx, loss_grad[l_idx],markersize=10,marker='o',color='red')\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.xlabel(\"Index of LRs\")\n",
    "        plt.show()\n",
    "\n",
    "        plt.plot(np.log10(lrs), losses)\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.xlabel(\"Log 10 Transform of Learning Rate\")\n",
    "        loss_coord = np.interp(np.log10(lr_to_use), np.log10(lrs), losses)\n",
    "        plt.plot(np.log10(lr_to_use), loss_coord, markersize=10,marker='o',color='red')\n",
    "        plt.show()\n",
    "        \n",
    "    return lr_to_use '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "22HZrVOeYWfd",
    "outputId": "68c50c29-5f63-4a65-d3f8-4b2b95eaa006"
   },
   "outputs": [],
   "source": [
    "model = EfficientNet.from_pretrained('efficientnet-b7', num_classes=data.c)\n",
    "model._fc = nn.Linear(in_features=2560, out_features=5, bias=True) #Attaching a Linear layer at the end to support 5 classes\n",
    "\n",
    "learn = Learner(data, model, metrics=[error_rate]).mixup().to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "22HZrVOeYWfd",
    "outputId": "68c50c29-5f63-4a65-d3f8-4b2b95eaa006"
   },
   "outputs": [],
   "source": [
    "learn.lr_find()\n",
    "learn.recorder.plot(suggestion=True)\n",
    "\n",
    "# One more step of manually choosing the learning rate\n",
    "\n",
    "lr = 1e-05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-thYTxkCOlP7"
   },
   "outputs": [],
   "source": [
    "#lr = find_appropriate_lr(learn, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "22HZrVOeYWfd",
    "outputId": "68c50c29-5f63-4a65-d3f8-4b2b95eaa006"
   },
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(20, max_lr = slice(lr) ,callbacks=[SaveModelCallback(learn)])\n",
    "learn.load('bestmodel')\n",
    "learn.save('efficient_net_b7_v2_best')\n",
    "\n",
    "#Analysis of the best model found\n",
    "learn.recorder.plot_losses()\n",
    "learn.recorder.plot_lr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "22HZrVOeYWfd",
    "outputId": "68c50c29-5f63-4a65-d3f8-4b2b95eaa006"
   },
   "outputs": [],
   "source": [
    "#Making all the layers trainable\n",
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "22HZrVOeYWfd",
    "outputId": "68c50c29-5f63-4a65-d3f8-4b2b95eaa006"
   },
   "outputs": [],
   "source": [
    "#training the unfreezed model\n",
    "learn.lr_find()\n",
    "learn.recorder.plot(suggestion=True)\n",
    "lr = 1e-05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "22HZrVOeYWfd",
    "outputId": "68c50c29-5f63-4a65-d3f8-4b2b95eaa006"
   },
   "outputs": [],
   "source": [
    "#lr = find_appropriate_lr(learn, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "22HZrVOeYWfd",
    "outputId": "68c50c29-5f63-4a65-d3f8-4b2b95eaa006"
   },
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(10, max_lr=slice(lr), callbacks=[SaveModelCallback(learn)])\n",
    "\n",
    "learn.load('bestmodel')\n",
    "learn.save('efficient_net_b7_v2_unfreeze_best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "for img_id in ids:\n",
    "    img = open_image('Processed_data/test/'+img_id+'.tif')\n",
    "    result.append(np.array(learn.predict(img)[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the Results in .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NnU_fNF3GS0T"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(result, columns = ['concrete_cement','healthy_metal','incomplete','irregular_metal','other'])\n",
    "df.insert(0,'id',ids)\n",
    "df.to_csv('Submission Form.csv',index = False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Model_Satellite_efficientnet.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
